[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Setting seed: 1
||||||||||Observe gait commands!
Converting heightmap to trimesh...
Created 4221682 vertices
Created 8443358 triangles
Adding trimesh to simulation...
Trimesh added
------------------------------------------------------
num_actions: 18
num_torques: 18
num_dofs: 20
num_bodies: 26
penalized_contact_names: ['FL_thigh', 'FR_thigh', 'RL_thigh', 'RR_thigh', 'FL_calf', 'FR_calf', 'RL_calf', 'RR_calf', 'trunk']
termination_contact_names: []
feet_names: ['FL_foot', 'FR_foot', 'RL_foot', 'RR_foot']
EE Gripper index: 24
penalized_contact_indices: tensor([ 2,  6, 10, 14,  3,  7, 11, 15, 17], device='cuda:0')
termination_contact_indices: tensor([], device='cuda:0', dtype=torch.int64)
feet_indices: tensor([ 4,  8, 12, 16], device='cuda:0')
------------------------------------------------------
root_states shape: torch.Size([3072, 13])
dof_state shape: torch.Size([61440, 2])
force_sensor_tensor shape: torch.Size([3072, 4, 6])
contact_forces shape: torch.Size([3072, 26, 3])
rigid_body_state shape: torch.Size([3072, 26, 13])
jacobian_whole shape: torch.Size([3072, 26, 6, 26])
box_root_state shape: torch.Size([3072, 13])
box_contact_force shape: torch.Size([3072, 3])
box_rigid_body_state shape: torch.Size([3072, 13])
------------------------------------------------------
Actor MLP: Actor(
  (priv_encoder): Sequential(
    (0): Linear(in_features=18, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=20, bias=True)
    (3): ELU(alpha=1.0)
  )
  (history_encoder): StateHistoryEncoder(
    (activation_fn): ELU(alpha=1.0)
    (encoder): Sequential(
      (0): Linear(in_features=71, out_features=30, bias=True)
      (1): ELU(alpha=1.0)
    )
    (conv_layers): Sequential(
      (0): Conv1d(30, 20, kernel_size=(4,), stride=(2,))
      (1): ELU(alpha=1.0)
      (2): Conv1d(20, 10, kernel_size=(2,), stride=(1,))
      (3): ELU(alpha=1.0)
      (4): Flatten(start_dim=1, end_dim=-1)
    )
    (linear_output): Sequential(
      (0): Linear(in_features=30, out_features=20, bias=True)
      (1): ELU(alpha=1.0)
    )
  )
  (actor_backbone): Sequential(
    (0): Linear(in_features=91, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
  )
  (actor_leg_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=12, bias=True)
  )
  (actor_arm_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=6, bias=True)
  )
)
Critic MLP: Critic(
  (critic_backbone): Sequential(
    (0): Linear(in_features=89, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
  )
  (critic_leg_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (critic_arm_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
)
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ActorCritic                              18
â”œâ”€Actor: 1-1                             --
â”‚    â””â”€Sequential: 2-1                   --
â”‚    â”‚    â””â”€Linear: 3-1                  1,216
â”‚    â”‚    â””â”€ELU: 3-2                     --
â”‚    â”‚    â””â”€Linear: 3-3                  1,300
â”‚    â”‚    â””â”€ELU: 3-4                     --
â”‚    â””â”€StateHistoryEncoder: 2-2          --
â”‚    â”‚    â””â”€ELU: 3-5                     --
â”‚    â”‚    â””â”€Sequential: 3-6              2,160
â”‚    â”‚    â””â”€Sequential: 3-7              2,830
â”‚    â”‚    â””â”€Sequential: 3-8              620
â”‚    â””â”€Sequential: 2-3                   --
â”‚    â”‚    â””â”€Linear: 3-9                  11,776
â”‚    â”‚    â””â”€ELU: 3-10                    --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-11                 16,512
â”‚    â”‚    â””â”€ELU: 3-12                    --
â”‚    â”‚    â””â”€Linear: 3-13                 16,512
â”‚    â”‚    â””â”€ELU: 3-14                    --
â”‚    â”‚    â””â”€Linear: 3-15                 1,548
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-16                 16,512
â”‚    â”‚    â””â”€ELU: 3-17                    --
â”‚    â”‚    â””â”€Linear: 3-18                 16,512
â”‚    â”‚    â””â”€ELU: 3-19                    --
â”‚    â”‚    â””â”€Linear: 3-20                 774
â”œâ”€Critic: 1-2                            --
â”‚    â””â”€Sequential: 2-6                   --
â”‚    â”‚    â””â”€Linear: 3-21                 11,520
â”‚    â”‚    â””â”€ELU: 3-22                    --
â”‚    â””â”€Sequential: 2-7                   --
â”‚    â”‚    â””â”€Linear: 3-23                 16,512
â”‚    â”‚    â””â”€ELU: 3-24                    --
â”‚    â”‚    â””â”€Linear: 3-25                 16,512
â”‚    â”‚    â””â”€ELU: 3-26                    --
â”‚    â”‚    â””â”€Linear: 3-27                 129
â”‚    â””â”€Sequential: 2-8                   --
â”‚    â”‚    â””â”€Linear: 3-28                 16,512
â”‚    â”‚    â””â”€ELU: 3-29                    --
â”‚    â”‚    â””â”€Linear: 3-30                 16,512
â”‚    â”‚    â””â”€ELU: 3-31                    --
â”‚    â”‚    â””â”€Linear: 3-32                 129
=================================================================
Total params: 166,116
Trainable params: 166,116
Non-trainable params: 0
=================================================================
################################################################################
                      [1m Learning iteration 0/36000 [0m

                       Computation: 23757 steps/s (collection: 2.616s, learning 0.488s)
               Value function loss: 0.0000
                    Surrogate loss: 0.0000
   History latent supervision loss: 1.0259
  Privileged info regularizer loss: 0.0000
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.93
         Arm mean action noise std: 1.00
     action noise std distribution: [[0.800000011920929, 1.0, 1.0, 0.800000011920929, 1.0, 1.0, 0.800000011920929, 1.0, 1.0, 0.800000011920929, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]
                       Mean reward: -0.48
               Mean episode length: 18.11
                             Dones: 0.00
      Mean episode rew_action_rate: -0.3822
            Mean episode rew_alive: 1.3417
       Mean episode rew_ang_vel_xy: -0.3837
      Mean episode rew_base_height: -0.5061
        Mean episode rew_collision: -0.4077
    Mean episode rew_delta_torques: -0.0002
          Mean episode rew_dof_acc: -2.1857
   Mean episode rew_dof_pos_limits: -0.0002
    Mean episode rew_feet_air_time: -0.2506
Mean episode rew_feet_contact_forces: -0.0043
        Mean episode rew_feet_drag: -0.1074
      Mean episode rew_feet_height: -0.2578
        Mean episode rew_feet_jerk: 0.0000
          Mean episode rew_hip_pos: -0.0631
        Mean episode rew_lin_vel_z: -1.5301
             Mean episode rew_roll: -0.2472
      Mean episode rew_stand_still: 0.1836
          Mean episode rew_torques: -0.4991
 Mean episode rew_tracking_ang_vel: 0.2046
Mean episode rew_tracking_contacts_shaped_force: 0.5824
Mean episode rew_tracking_contacts_shaped_vel: 0.5792
Mean episode rew_tracking_lin_vel_max: 0.0997
      Mean episode rew_walking_dof: 1.4966
             Mean episode rew_work: -0.8176
Mean episode rew_tracking_ee_world: 0.4836
   Mean episode metric_action_rate: 25.4773
         Mean episode metric_alive: 1.3417
    Mean episode metric_ang_vel_xy: 7.6738
   Mean episode metric_base_height: 0.3801
     Mean episode metric_collision: 0.2039
 Mean episode metric_delta_torques: 2494.4131
       Mean episode metric_dof_acc: 2914280.0000
Mean episode metric_dof_pos_limits: 0.0000
 Mean episode metric_feet_air_time: -0.1253
Mean episode metric_feet_contact_forces: 4.2945
     Mean episode metric_feet_drag: 3.5816
   Mean episode metric_feet_height: -0.2578
     Mean episode metric_feet_jerk: 0.0000
       Mean episode metric_hip_pos: 0.2103
     Mean episode metric_lin_vel_z: 1.0200
          Mean episode metric_roll: 0.1236
   Mean episode metric_stand_still: 0.1836
       Mean episode metric_torques: 1996.4695
Mean episode metric_tracking_ang_vel: 1.5495
Mean episode metric_tracking_contacts_shaped_force: -0.1941
Mean episode metric_tracking_contacts_shaped_vel: -0.5792
Mean episode metric_tracking_lin_vel_max: 0.1994
   Mean episode metric_walking_dof: 0.9978
          Mean episode metric_work: 272.5387
Mean episode metric_tracking_ee_world: 0.5498
--------------------------------------------------------------------------------
                   Total timesteps: 73728
                    Iteration time: 3.10s
                        Total time: 3.10s
                               ETA: 111719.6s
Traceback (most recent call last):
  File "train.py", line 65, in <module>
    train(args)
  File "train.py", line 61, in train
    ppo_runner.learn(num_learning_iterations=train_cfg.runner.max_iterations, init_at_random_ep_len=True)
  File "/home/irl/visual_wholebody/third_party/rsl_rl/rsl_rl/runners/on_policy_runner.py", line 138, in learn
    obs, privileged_obs, rewards, arm_rewards, dones, infos = self.env.step(actions)
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 107, in step
    self.post_physics_step()
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 156, in post_physics_step
    self.compute_observations() # in some cases a simulation step might be required to refresh some obs (for example body positions)
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 222, in compute_observations
    obs_buf = torch.cat((       self._get_body_orientation(),  # dim 2
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 1117, in _get_body_orientation
    r, p, y = euler_from_quat(self.base_quat)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 65, in <module>
    train(args)
  File "train.py", line 61, in train
    ppo_runner.learn(num_learning_iterations=train_cfg.runner.max_iterations, init_at_random_ep_len=True)
  File "/home/irl/visual_wholebody/third_party/rsl_rl/rsl_rl/runners/on_policy_runner.py", line 138, in learn
    obs, privileged_obs, rewards, arm_rewards, dones, infos = self.env.step(actions)
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 107, in step
    self.post_physics_step()
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 156, in post_physics_step
    self.compute_observations() # in some cases a simulation step might be required to refresh some obs (for example body positions)
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 222, in compute_observations
    obs_buf = torch.cat((       self._get_body_orientation(),  # dim 2
  File "/home/irl/visual_wholebody/low-level/legged_gym/envs/manip_loco/manip_loco.py", line 1117, in _get_body_orientation
    r, p, y = euler_from_quat(self.base_quat)
KeyboardInterrupt
